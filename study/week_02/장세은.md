# 3.1 카프카 브로커.클러스터.주키퍼

## 브로커

- 카프카 클라이언트와 데이터를 주고받기 위해 사용하는 주체이자, 데이터를 분산 저장하여 장애가 발생하더라도 안전하게 사용할 수 있도록 도와주는 애플리케이션이다.
- 하나의 서버에는 한 개의 카프카 브로커 프로세스가 실행된다.
- 카프카 브로커 서버 1대로도 기본 기능이 실행되지만 데이터를 안전하게 보관하고 처리하기 위해 3대 이상의 브로커 서버를 1개의 클러스터로 묶어서 운영한다.
- 카프카 클러스터로 묶인 브로커들은 프로듀서가 보낸 데이터를 안전하게 분산 저장하고 복제하는 역할을 수행한다.

### 데이터 저장, 전송

- 프로듀서로부터 데이터를 전달받으면 카프카 브로커는 프로듀서가 요청한 토픽의 파티션에 데이터를 저장하고 컨슈머가 데이터를 요청하면 파티션에 저장된 데이터를 전달한다.
- 프로듀서로부터 전달된 데이터는 파일 시스템에 저장된다.
- 카프카는 메모리나 데이터베이스에 저장하지 않으며 따로 캐시메모리를 구현하여 사용하지도 않는다.
- 카프카는 페이지 캐시를 사용하여 디스크 입출력 속도를 높였고, 이러한 특징 때문에 카프카 브로커를 실행하는데 힙 메모리 사이즈를 크게 설정할 필요가 없다.

### 데이터의 복제, 싱크

- 데이터 복제는 카프카를 장애 허용 시스템으로 동작하도록 하는 원동력이다.
- 복제의 이유는 클러스터로 묶인 브로커 중 일부에 장애가 발생하더라도 데이터를 유실하지 않고 안전하게 사용하기 위함이다.
- 카프카의 데이터 복제는 파티션 단위로 이루어진다. 토칙을 생성할 때 파티션의 복제 개수도 같이 설정되는데 직접 옵션을 선택하지 않으면 브로커에 설정된 옵션 값을 따라간다.
- 복제 개수의 최솟값은 1이고 최댓값은 브로커 개수만큼 설정하여 사용할 수 있다.
- 복제된 파티션은 리더와 팔로워로 구성된다. 프로듀서 또는 컨슈머와 직접 통신하는 파티션을 리더, 나머지 복제 데이터를 가지고 있는 파티션을 팔로워라고 부른다.
- 팔로워는 리더의 오프셋을 확인해 현재 자신이 가지고 있는 오프셋과 차이가 나는 경우 리더로 부터 데이터를 가져와 자신의 파티션에 저장을 하는데 이 과정을 복제 (replication)이라고 부른다.
- 파티션 복제로 인해 나머지 브로커에도 파티션의 데이터가 복제되므로 복제 개수만큼의 저장 용량이 증가한다는 단점이 있다.
- 운영 중 리더 파티션이 있는 브로커가 다운되면 해당 브로커에 있는 리더는 사용할 수 없기 때문에 팔로워 중 하나가 리더 지위를 넘겨받게 된다. 이를 통해 데이터가 유실되지 않는다.
- 운영 시에는 데이터 종류마다 다른 복제 개수를 설정하고 상황에 따라서는 토픽마다 복제 개수를 다르게 설정하여 운영하기도 한다.
- 데이터가 일부 유실되어도 무관하고 데이터 처리 속도가 중요하다면 복제 개수를 1 또는 2로 설정한다.
- 금융 정보와 같이 유실이 일어나면 안 되는 데이터의 경우 복제 개수를 3으로 설정하여 최대 2개의 브로커에서 동시에 장애가 발생하더라도 데이터를 안정적으로 유지할 수 있도록 한다.

### 컨트롤러

- 클러스터의 다수 브로커 중 한 대가 컨트롤러의 역할을 한다.
- 컨트롤러는 다른 브로커들의 상태를 체크하고 브로커가 클러스터에서 빠지는 경우 해당 브로커에 존재하는 리더 파티션을 재분배한다.
- 카프카는 지속적으로 데이터를 처리해야 하므로 브로커의 상태가 비정상이라면 빠르게 클러스터에서 빼내는 것이 중요하다.
- 만약 컨트롤러 역할을 하는 브로커에 장애가 발생하면 다른 브로커가 컨트롤러 역할을 한다.

### 데이터 삭제

- 카프카는 다른 메시징 플랫폼과 다르게 컨슈머가 데이터를 가져가더라도 토픽의 데이터는 삭제되지 않는다. 또한 컨슈머나 프로듀서가 데이터 삭제를 요청할 수도 없다. 오직 브로커만이 삭제가 가능하다.
- 데이터 삭제는 파일 단위로 이루어지는데 이 단위를 ‘로그 세그먼트’라고 부른다. 이 세그먼트에는 다수의 데이터가 들어 있기 때문에 일반적인 데이터베이스처럼 특정 데이터를 선별해서 삭제할 수 없다.

### 컨슈머 오프셋 저장

- 컨슈머 그룹은 토픽이 특정 파티션으로부터 데이터를 가져가서 처리하고 이 파티션의 어느 레코드까지 가져갔는지 확인하기 위해 오프셋을 커밋한다.
- 커밋한 오프셋은 _consumer_offsets 토픽에 저장되고, 여기에 저장된 오프셋을 토대로 컨슈머 그룹은 다음 레코드를 가져가서 처리한다.

### 코디네이터

- 클러스터의 다수 브로커 중 한 대는 코디네이터의 역할을 수행한다. 코디네이터는 컨슈머 그룹의 상태를 체크하고 파티션을 컨슈머와 매칭되도록 분배하는 역할을 한다.
- 컨슈머가 컨슈머 그룹에서 빠지면 매칭되지 않은 파티션을 정상 동작하는 컨슈머로 할당하여 끊임없이 데이터가 처리되도록 도와준다. 이를 리밸런스라고 부른다.

# 3.2 토픽과 파티션

- 토픽은 카프카에서 데이터를 구분하기 위해 사용하는 단위이다.
- 토픽은 1개 이상의 파티션을 소유하고 있다.
- 파티션에는 프로듀서가 보낸 데이터들이 들어가 저장되는데 이 데이터를 레코드라고 부른다.
- 파티션은 카프타의 병렬처리의 핵심으로써 그룹으로 묶인 컨슈머들이 레코드를 병렬로 처리 할 수 있도록 매칭된다.
    - 컨슈머의 처리량이 한정된 상황에서 많은 레코드를 병렬로 처리하는 가장 좋은 방법은 컨슈머의 개수를 늘려 스케일 아웃하는 것이다. 컨슈머 개수를 늘림과 동시에 파티션 개수도 늘리면 처리량이 증가하는 효과를 볼 수 있다.
- 파티션은 자료구조에서 접하는 큐와 비슷한 구조라고 생각하면 쉽다. FIFO 구조와 같이 먼저 들어간 레코드는 컨슈머가 먼저 가져가게 된다.
- 다만, 일반적인 자료구조로 사용되는 큐는 데이터를 가져가면(pop) 레코드를 삭제하지만 카프카에서는 삭제하지 않는다.
    - 파티션의 레코드는 컨슈머가 가져가는 것과 별개로 관리된다. 이러한 특징 때문에 토픽의 레코드는 다양한 목적을 가진 여러 컨슈머 그룹들이 토픽의 데이터를 여러 번 가져 갈 수 있다.

# 3.3 레코드

- 레코드는 타임스탬프, 메시지 키, 메시지 값, 오프셋, 헤더로 구성되어 있다.
- 프로듀서가 생성한 레코드가 브로커로 전송되면 오프셋과 타임스탬프가 지정되어 저장된다.
- 브로커에 한번 적재된 레코드는 수정할 수 없고 로그 리텐션 기간 또는 용량에 따라서만 삭제된다.

---

**타임스탬프**

- 타임스탬프는 프로듀서에서 해당 레코드가 생성된 시점의 유닉스 타임이 설정된다. 컨슈머는 레코드의 타임스탬프를 토대로 레코드가 언제 생성되었는지 알 수 있다.

---

**메세지 키**

- 메세지 키는 메시지 값을 순서대로 처리하거나 메시지 값의 종류를 나타내기 위해 사용한다.
    - 메시지 키를 사용하면 프로듀서가 토픽에 레코드를 전송할 때 메시지 키의 해시값을 토대로 파티션을 지정하게 된다. 즉, 동일한 메시지 키라면 동일 파티션에 들어가는 것이다.
    - 다만, 어느 파티션에 지정될지 알 수 없고 파티션 개수가 변경되면 메시지 키와 파티션 매칭이 달라지게 되므로 주의해야 한다.
    - 만약 메시지 키를 사용하지 않는다면 선언하지 않으면 된다. 이때 메시지 키를 선언하지 않으면 null로 설정되고, 프로듀서 기본 설정 파티셔너에 따라 파티션에 분배되어 적재된다.

    ---


**메시지 값**

- 메시지 값에는 실질적으로 처리할 데이터가 들어 있다.
- 메시지 키와 메시지 값은 직렬화되어 브로커로 전송되기 때문에 컨슈머가 이용할 때는 직렬화한 형태와 동일한 형태로 역직렬화를 수행해야 한다.

---

**오프셋**

- 레코드의 오프셋은 0 이상의 숫자로 이루어져 있다.
- 레코드의 오프셋은 직접 지정할 수 없고 브로커에 저장될 때 이전에 전송된 레코드의 오프셋 + 1 값으로 생성된다.
- 오프셋은 카프카 컨슈머가 데이터를 가져갈 때 사용된다.
- 오프셋을 사용하면 컨슈머 그룹으로 이루어진 카프카 컨슈머들이 파티션의 데이터를 어디까지 가져갔는지 명확하게 지정할 수 있다.

---

**헤더**

- 레코드의 추가적인 정보를 담는 메타데이터 저장소 용도로 사용된다.
- 헤더는 키/값 형태로 데이터를 추가하여 레코드의 속성을 저장하여 컨슈머에서 참조할 수 있다.

# 3.4 카프카 클라이언트

## 3.4.1 프로듀서 API

- 카프카에서 데이터의 시작점은 프로듀서이다.
- 프로듀서 애플리케이션은 카프카에 필요한 데이터를 선언하고 브로커의 특정 토픽의 파티션에 전송한다.
- 프로듀서는 데이터를 전송할 때 리더 파티션을 가지고 있는 카프카 브로커와 직접 통신한다.
- 프로듀서는 데이터를 직렬화하여 카프카 브로커로 보내기 때문에 자바에서 선언 가능한 모든 형태를 브로커로 전송할 수 있다.

### 프로듀서 주요 옵션

**필수옵션**

- bootstrap.servers: 프로듀서가 데이터를 전송할 대상 카프카 클러스터에 속한 브로커의 호스트 이름으로 포트를 1개 이상 작성한다. 2개 이상 브로커 정보를 입력하여 일부 브로커에 이슈가 발생하더라도 접속하는 데에 이슈가 없도록 설정 가능하다.
- key.serializer: 레코드의 메시지 키를 직렬화하는 클래스를 지정한다.
- value.serializer: 레코드의 메시지 값을 직렬화하는 클래스를 지정한다.

**선택옵션**

- asks: 프로듀서가 전송한 데이터가 브로커들에 정상적으로 저장되었는지 전송 성공 여부를 확인하는데에 사용하는 옵션
- buffer.memory : 브로커로 전송할 데이터를 배치로 모으기 위해 설정할 버퍼 메모리양을 지정한다.
- retries: 프로듀서가 브로커로부터 에러를 받고 난 뒤 재전송을 시도하는 횟수를 지정한다.
- batch.size: 배치로 전송할 레코드 최대 용량을 지정한다.
- linger.ms: 배치를 전송하기 전까지 기다리는 최소 시간
- partitioner.class: 레코드를 파티션에 전송할 때 적용하는 파티셔너 클래스
- enable.idempotnece: 멱등성 프로듀서로 동작할지 여부를 설정한다.
- transactional.id: 프로듀서가 레코드를 전송할 때 레코드를 트랜잭션 단위로 묶을지 여부를 설정한다. 프로듀서의 고유한 트랜잭션 아이디를 설정할 수 있다.
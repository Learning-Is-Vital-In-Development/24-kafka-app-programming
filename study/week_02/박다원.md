챕터 3에서는 카프카의 역사와 각 컴퓨넌트들으리 특징, 관련 생태계에 대해 설명한다. 

# 3.1  카프카 브로커 / 클러스터 / 주키퍼

### 데이터 저장 전송

카프카 브로커는 카프카 클라이언트와 데이터를 주고받기 위해 사용하는 주체이자. 

데이터를 분산 저장하여 장애가 발생하더라도 안전하게 사용할 수 있게 도와주는 애플리케이션이다. 

- 하나의 서버에는 한개의 카프카 브로커 프로세스가 실행
- 브로커 서버 1대로도 실행 가능하지만  데이터를 안전하게 보관하기 위해 3대이상 브로커 서버를 1개의 클러스터로 묶어 운영
- 카프카 클러스터로 묶인 브로커들은 프로듀서가 보낸 데이터를 안전하게 분산저장 및 복제하는 역할 수행

프로듀서 데이터 전달받기 → 카프카 브로커는 프로듀서가 요청한 토픽 파티션에 데이터 저장 → 컨슈머가 데이터 요청→ 파티션에 저장한 데이터 전달 

카프카는 메모리나 데이터 베이스에 저장하지 않고 캐시메모리 구현도 하지않음

- 파일 시스템에 저장하기 때문에 파일 입출력으로 인해 속도 이슈가 발생하지 않을까 의문을 가질 수 있으나 
카프카는 페이지 캐시를 사용하여 디스크 입출력 속도를 높여 이를 해결함.
    - 파일 시스템은 다루기 편하지만 지속적으로 입출력할 경우 메모리에 올려서 쓰는 것보다 속도가 느리기 때문에 속도 이슈 제기
    - `페이지 캐시?` : OS에서 파일 입출력의 성능 향상을 위해 만들어놓은 메모리 영역
        - 추후 동일한 파일 접근 시 디스크에서 읽지 않고 메모리에서 직접 읽는 방식
        - JVM 위에서 동작하는 카프카 브로커가 페이지 케시를 사용하지 않는다면 지금과 같이 빠른 동작을 기대할 수 없다. 페이지캐시를 사용하지 않으면 카프카에서 캐시를 직접 구현해야했을 것이고 지속적으로 변경되는 데이터 때문에 가비지 컬렉션이 자주 일어나 속도가 현저히 느려질 것이다. 
        → 이러한 특징 때문에 카프카 브로커를 실행하는데 힙 메모리 사이즈를 크게 설정할 필요가 없다.

### 데이터 복제 싱크

데이터 복제 replication은 카프카를 장애 허용 시스템(fault tolerant system)으로 동작하도록 하는 원동력이다. 

- 복제의 이유는 클러스터로 묶인 브로커 중 일부에 장애가 발생하더라도 데이터를 유실하지 않고 안전하게 사용하기 위함
    - 카프카 데이터 복제는 파티션 단위로 이루어짐
    - 토픽 생성 시 파티션 복제 개수(replication factor)도 같이 설정되는데 직접 옵션을 선택하지 않으면 브로커에 설정된 옵션값을 따라간다.
    - 복제 개수의 최솟값은 1이고 최댓값은 브로커 개수만큼 설정하여 사용할 수 있다.

프로듀서 또는 컨슈머와 직접 통신하는 파티션을 리더, 나머지 복제 데이터를 가지고 있는 파티션을 팔로워라고 부른다. 

- 파티션 리더 : 리더 파티션
- 파티션 팔로워 : 팔로워 파티션
    - 리더 파티션의 오프셋 확인해서 현재 자신이 가지고 있는 오프셋과 차이가 나는 경우 리더 파티션으로부터 데이터를 가져와 자신의 파티션에 저장 → `복제(replication)`이라 칭함
    - 파티션 복제로 브로커에서도 파티션 데이터가 복제되어 복재 개수만큼 저장용량이 증가한다는 단점이 있지만 데이터를 안전하게 저장할 수 있기 때문에 **카프카 운영시 복제 개수를 2이상으로 설정**하는것이 중요
    - 데이터 일부 유실되어도 상관없고 처리속도가 중요하다면 1,2 로 설정 
    → 금융의 경우 복제 개수 3으로 설정하여 2개의 브로커에서 동시 장애발생해도 데이터 안정적으로 유지
- 컨트롤러(controller)
    - 클러스터의 다수 브로커 중 한대가 컨트롤러의 역할을 함
        - 컨트롤러는 다른 브로커들의 상태를 체크하고 브로커가 클러스터에서 빠지는 경우 해당 브로커에 존재하는 리더 파티션을 재분배한다.
        - 컨트롤러 역할 브로커가 장애가 생기면 다른 브로커가 이를 대신함

### 데이터 삭제

카프카는 다른 메시징 플랫폼과 다르게 컨슈머가 데이터 가져가더라도 토픽의 데이터는 삭제 되지 않음

- 컨슈머나 프로듀서가 데이터 삭제 요청 못함 → 오직 브로커만 가능
- 데이터 삭제는 파일 단위 : log segment라 칭함
    - 이 세그먼트에서는 다수 데이터가 존재하여 일반적 데이터베이스처럼 특정 데이터 선별하여 삭제가 안됨
    - 세그먼트는 데이터가 쌓이는 동안 파일 시스템으로 열려있으며 카프카 브로커에 log.segment.bytes, [log.segments.ms](http://log.segments.ms) 옵션값이 **설정되면 세그먼트 파일이 닫힘** (파일닫히는 기본값은 1GB 용량도달시 닫힘)

### 컨슈머 오프셋 저장

컨슈머 그룹은 토픽이 특정 파티션으로 데이터 가져가서 처리하고 이 파티션은 어느 레코드까지 가져갔는지 확인하기 위해 오프셋을 커밋

- 커밋한 오프셋은 __consumer_offset 토픽에서 저장
- 여기 저장된 오프셋을 토대로 컨슈머 그룹은 다음 레코드를 가져가 처리함

### 코디네이터(coordinator)

클러스터 다수 브로커 중 한대는 코디네이터 역할 수행 

- 컨슈머 그룹 상태 체크
- 파티션을 컨슈머와 매칭되도록 분배함
    - 컨슈머가 컨슈머 그룹에서 빠지면 매칭되지 않은 파티션을 정상 컨슈머로 할당하여 끊임없이 데이터가 처리되도록 도움

→ 파티션을 컨슈머로 재할당하는 과정을 리밸런스(rebalnace)라 칭함 

⇒ 여기까지 브로커의 역할에 대해서 알아봄, 이제 주키퍼의 역할? 

---

주키퍼의 역할

- 카프카의 메타 데이터를 관리하는데 사용된다.
- 주키퍼 쉘 명령어를 실행하여 어떤 데이터 저장하는지 확인해보자
    ![image-1721287311934 jpg2713794556359070903](https://github.com/user-attachments/assets/689e4ce1-7baa-4d8f-92a1-fc46df2a4044)

    - 카프카 클러스터로 묶인 브로커들은 동일한 경로의 주키퍼 경로로 선언해야 같은 카프카 브로커 묶음이 된다. 만약 클러스터를 여러 개로 운영한다면 한 개의 주키퍼에 다수의 카프카 클러스터를 연결해서 사용할 수 있다.
    - 주키퍼에서 다수 카프카 클러스터 사용하기
        - 주키퍼의 서로다른 znode에 카프카 클러스터 설정 (znode란 주키퍼 데이터저장단위)

# 3.2 토픽과 파티션

토픽은 카프카에서 데이터 구분을 위해 사용되는 단위이다. 

- 토픽은 1개 이상의 파티션을 소유
- 파티션
    - 파티션에는 프로듀서가 보낸 데이터가 들어가 저장됨 → 데이터를 “레코드”라 칭함
    - 파티션은 카프카의 병렬 처리 핵심으로써 그룹에 묶인 컨슈머들이 레코드를 병렬로 처리할 수 있도록 매칭됨
    - 레코드 별렬 처리 추천 방법) 컨슈머 개수 늘려 스케일 아웃 → 컨슈머 늘리면서 파티션 개수 늘리면 처리량 증가효과 보임
    - 파티션은 자료구조에서 큐(queue)와 비슷한 구조임
        - first in first out 구조와 같이 먼저 들어간 레코드는 컨슈머가 먼저 가져감
        - 하지만 큐와 다르게 데이터가 pop되지않음
- 토픽 이름 제약 조건
    - 최소한 토픽 이름을 통해 어떤 개발환경에서 사용되는 것인지 판단 가능해야되고 어떤 애플리케이션에서 어떤 데이터 타입으로 사용되는지 유추할 수 있어야함
    - 대문자와 소문자 섞어쓰는 카멜케이스보다 케밥/스네이크 표기법 추천
        - <환경><팀-명><애플리케이션-명><메시지-타입>
            - prd.marketing-team.sms-platfrom.json
        - <프로젝트-명><서비스-명><환경><이벤트-명>
            - commerce.payment.prd.notification
        - <환경><서비스-명><JIRA-번호><메시지-타입>
            - dev.email-sender.jira-1234.email-vo-custom
    - 제약 리스트
        - + 이미 생성된 토픽의 이름을 . → 로 변경 안됨 ( to.pic → to_pic) 변경 안됨
        ![image-1721287311934 jpg2713794556359070903](https://github.com/user-attachments/assets/9d4f36eb-1335-40ae-9349-46d22c35574b)

        

# 3.3 레코드

레코드는 타임스탬프 , 메시지 키, 메시지 값, 오프셋, 헤더로 구성되어있다.

프로듀서가 생성한 레코드가 브로커로 전송되면 오프셋과 타임스탬프가 지정되어 저장된다. 

- 브로커에 한번 적재된 레코드는 수정할 수 없고 로그 리텐션 기간또는 용량에 따라서만 삭제된다.

### 타임스탬프

프로듀서에서 해당 레코드가 생성된 시점(createtime)의 유닉스 타임이 설정됨

- 컨슈머는 레코드의 타임스탬프를 토대로 레코드가 언제 생성되었는지 알 수 이다. 다만 프로듀서가 임의의 타임스탬프 값 성절가능
- 토픽에 따라 브로커에 적재된 시간(Logappendtime)으로 설정될 수 있다는 점 유의

### 메시지 키

값을 순서대로 처리하거나 메시지 값의 종류를 나타내기 위해 사용한다

메시지 키를 사용하면 프로듀서가 토픽에 레코드를 전송할 때 메시지 키의 해시값 토대로 파티션 지정하게 된다

- 동일 메세지 키는 동일 파티션에 들어감 (다만 어느 파티션인지 알 수 없고 파티션 개수 변경되면 메시지 키와 파티션 매칭이 달라지게 되므로 주의)
- 메시지 키 사용 안하면 프로듀서에서 레코드를 전송할 때 메시지 키를 선언하지 않으면 된다.
    - 선언 안하면 null 이됨→ null인 레코드는 기본 설정 파티셔너에 따라 파티션에 분배되어 적재됨
- 메시지 값에는 실질적으로 처리할 데이터가 있으며 메시지키와 값이 직렬화되어 브로커로 전송되기 때문에 컨슈머가 이용할 떄는 직렬화한 형태와 동일하게 역질렬화 해야함

### 오프셋

- 오프셋은 카프카 컨슈머가 데이터를 가져갈 때 사용된다. 오프셋 사용하면 컨슈머 그룹으로 이루어진 카프카 컨슈머들이 파티션의 데이터를 어디까지 가져갔는지 명확하게 지정가능하다.

### 헤더

- 레코드의 추가적인 정보를 담는 메타데이터 저장소 용도로 사용한다.
- 헤더는 키/값 형태로 데이터를 추가하여 레코드의 속성(스키마 버전)을 저장하여 컨슈머에서 참조할 수 있다.

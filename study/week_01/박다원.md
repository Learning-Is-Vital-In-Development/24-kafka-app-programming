# [CH1-2] 들어가며, 카프카 시작하기

## 0. 서론

이번 챕터에서는 카프카를 설치하고 토픽을 생성, 수정하고 데이터를 전송(프로듀서)하고 받는(컨슈머)실습을 진행한다. 

 

## 1. 카프카란?

**카프카(Kafka)** 는 파이프라인, 스트리밍 분석, 데이터 통합 및 미션 크리티컬 애플리케이션을 위해 설계된 **고성능 분산 이벤트 스트리밍 플랫폼**이다.

**Pub-Sub 모델의 메시지 큐** 형태로 동작하며 분산환경에 특화되어 있다.

Fortune 100개 기업 중 80% 이상이 Kafka를 사용한다. 국내에서도 많이 사용하는 추세다.

> **카프카가 탄생하게 된 계기** 

- 카프카는 비즈니스 소셜 네트워크 서비스인 링크드인 (linked-in) 에서 개발함.
- 각 애플리케이션과 DB가 end-to-end 로 연결되어 있고(각 파이프라인이 파편화 되어있음), 요구사항이 늘어남에 따라 데이터 시스템 복잡도가 높아지면서 다음과 같은 문제가 발생하게 되었다.
    - 시스템 복잡도 증가 (**Complexity)**
    - 데이터 파이프라인 관리 어려움

→ 모든 시스템으로 데이터를 전송할 수 있고, 실시간 처리도 가능하며, 급속도로 성장하는 서비스를 위해 확장이 용이한 시스템을 만들자!


> **실습**

카프카를 안전하게 서비스로 운영하기 위해서는 최소 3개의 서버로 카프카 클러스터를 구축해야한다.

 그러나 실습해서는 1대로도 충분하다

실습 위해 실행되는 프로세스는 주키퍼와 카프카 브로커 이다. 

- 주키퍼 : 아파치 소프트웨어재단 프로젝트
    - 분산 코디네이션 서비스를 제공하는 오픈소스
        - *분산 코디네이션 서비스 : 내부에 상태정보를 저장하고 데이터를 key/value 저장소로 저장 및 제공하는 서비스를 지칭하는 것
    - 주키퍼는 카프카의 클러스터 설정 리더 정보, 컨트롤러 정보를 담고 있어 카프카를 실행하는데에 필요한 필수 애플리케이션이다.
    - 실습에서는서버에 카프카와 동시에 1대만 실행시켜 사용할 것이다.(상용은 안전하게 3대) → Quick-and-dirty single-node’라 지칭한다.

카프카에서는 주키퍼를 운영에 필요한 각종 설정과 상태들을 저장하는데 사용하고 있다. 

`주키퍼`와 `카프카브로커`는 JVM위에서 돌아가는 애플레이션

- 힙 메모리(heap memory)를 지정해야한다.

## 2. 카프카 커맨드 라인 툴

카프카를 운영할 때 가장 많이 접하는 도구 

- 카프카 클라이언트 애플리케이션을 운영할 떄는 카프카 클러스터와 연동하여 데이터를 주고 받는 것도 중요하지만
- 토픽이나 파티션 개수 변경과 같은 명령을 실행해야하는 경우도 자주 발생한다.

→ 때문에 커맨드라인과 툴 옵션에 대해 잘 알고 있어야함 

> **TIP)** 커맨드 라인 툴 사용하기 전에 현재 브로커에 옵션이 어떻게 설정되어 있는지 확인 후 사용하면 커맨드 라인 툴 사용 시 실수할 확률이 줄어든다.
### 2-1. Docker Compose 설정 파일 (`docker-compose.yml`)

```sql
services:
  zookeeper:
    image: wurstmeister/zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    restart: always

  kafka:
    image: wurstmeister/kafka:2.12-2.5.0
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_HOST_NAME: 127.0.0.1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://127.0.0.1:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    restart: always

docker compose up -d #카프카 및 주키퍼 컨테이너 시작 (yml 해당 파일구성으로 시작한다.)
docker compose ps #컨테이너 상태확인
```

### 2-2. kafka 토픽 생성 및 메시지 테스트

```sql
docker compose exec kafka /bin/bash

# 토픽 생성
kafka-topics.sh --create --topic test --bootstrap-server 127.0.0.1:9092 --replication-factor 1 --partitions 1

# 데이터 전송
kafka-console-producer.sh --topic test --bootstrap-server 127.0.0.1:9092

# 데이터 수신 (topic test에 전송한 메세지를 출력할 것임)  
kafka-console-consumer.sh --topic test --bootstrap-server 127.0.0.1:9092 --from-beginning
```

`topics.sh`

커맨드 라인 툴을 통해 토픽과 관련된 명령어 실행 가능 

- 토픽이란? 카프카에서 데이터를 구분하는 가장 기본적인 개념
    - RDMBS 에서 사용하는 테이블과 유사하다.
    - 카프카 클러스터에 토픽은 여러개 존재할 수 있다.
    - 파티션이 존재하며 파티션의 개수는 최소 한개부터 시작한다.

> 토픽 생성 방법

- 카프카 컨슈머 또는 프로듀서가 카프카 브로커에 생성되지 않은 토픽에 대해 데이터를 요청할 때
- 커맨드 라인 툴로 명시적으로 토픽을 생성하는 것 → 토픽 유지보수를 위해 해당 방법 추천

> 토픽 리스트 조회 / 상세 조회 

- -list 옵션을 사용하여 토픽이 몇개나 얼마나 생성되었는지 확인 가능하다.
    - 내부 관리 위한 인터널 토픽(internal topic)은 운영에 사용되지 않으므로 —exclude-internal 사용해서 제거가 가능하다.
- -describe 옵션 사용해서 파티션 개수 , 복재된 파티션이 위치한 브로커 번호, 기타 토픽을 구성하는 설정들을 출력한다.

```bash
###토픽 생성
kafka-topics.sh \
--create \
--topic test
--bootstrap-server 127.0.0.1:9092 \
#복제 브로커 수 Kafka는 각 파티션의 복제본을 몇 개의 브로커에 저장할지 결정
--replication-factor 1 \ 
# 파티션 수 증가시키면 Kafka가 처리할 수 있는 메시지 처리량을 늘릴 수 있음.default 1
--partitions 1 
#(2일) 토픽 데이터유지기간, topics.sh에 포함되지 않은 추가적 설정 가능 
--config retention.ms=1728000000 

### test 토픽에 데이터를 넣을 수 있는 kafaka-console-producer.sh 명령어 실행
kafka-console-producer.sh \
 --topic test \
 --bootstrap-server 127.0.0.1:9092
```

> 토픽 옵션 변경

옵션 변경을 하기 위해서는 topics.sh와 config.sh 두개를 사용해야한다.

- 파티션 개수 변경 시 → topics.sh
- 토픽 삭제 정책인 리텐션 기간을 변경 → configs.sh

## 3. 실습 

<img width="724" alt="image" src="https://github.com/user-attachments/assets/ae74de8b-594c-42ed-8917-c24cbfab7cc9">

## 챕터 3.5~3.6

### 카프카 스트림즈

카프카 스트림즈는 토픽에 적재된 데이터를 상태기반 또는 비상태기반으로 실시간으로 변환하여 다른 토픽에 적재하는 라이브러리이다.

카프카 스트림즈를 사용하는 이유

- 카프카에서 공식적으로 지원하는 라이브러리 ⇒ 버전 이슈가 적음

특징

- 스트림즈 애플리케이션은 내부적으로 스레드를 1개 이상 생성할 수 있으며, 스레드는 1개 이상의 태스크를 가진다.

태스크

- 스트림즈 애플리케이션을 실행하면 생기는 데이터 처리 최소 단위이다.

카프카 스트림즈는 컨슈머 스레드를 늘리는 방법과 동일하게 병렬처리를 위해 파티션과 스트림즈 스레드 개수를 늘림으로써 처리량을 늘릴 수 있다.

실제 운영환경에서는 장애가 발생하더라도 안정적으로 운영할 수 있도록 2개 이상의 서버로 구성하여 스트림즈 애플리케이션을 운영한다.

토폴로지

- 2개 이상의 노드들과 선으로 이루어진 집합을 뜻함.

토폴로지 종류

- 링형
- 트리형
- 성형

스트림즈에서 사용하는 토폴로지는 트리 형태와 유사하다.

스트림즈에서 토폴로지를 이루는 노드를 하나의 프로세서 라고 부르고, 노드와 노드를 이은 선을 스트림이라고 부른다.

스트림

- 토픽의 데이터를 뜻하는데, 프로듀서와 컨슈머에서 활용했던 레코드와 동일하다.

프로세서

- 소스 프로세서
    - 데이터를 처리하기 위해 최초로 선언해야 하는 노드로, 하나 이상의 토픽에서 데이터를 가져오는 역할
- 스트림 프로세서
    - 다른 프로세서가 반환한 데이터를 처리하는 역할
    - 변환, 분기처리와 같은 로직이 데이터 처리의 일종이라고 볼 수 있다.
- 싱크 프로세서
    - 데이터를 특정 카프카 토픽으로 저장하는 역할을 하며 스트림즈로 처리된 데이터의 최종 종착지

스트림즈DSL로 구현하는 데이터 처리 예시

- 메시지 값을 기반으로 토픽 분기 처리
- 지난 10분간 들어온 데이터의 개수 집계
- 토픽과 다른 토픽의 결합으로 새로운 데이터 생성

프로세서 API로 구현하는 데이터 처리 예시

- 메시지 값의 종류에 따라 토픽을 가변적으로 전송
- 일정한 시간 간격으로 데이터 처리

스트림즈DSL

레코드의 흐름을 추상화한 3가지 개념인 KStream, KTable, GlobalKTable이 있다.

KStream

- 레코드의 흐름을 표현한 것, 메세지 키와 메시지 값으로 구성
- KStream으로 데이터를 조회하면 토픽에 존재는 모든 레코드가 출력
- 컨슈머로 토픽을 구독하는 것과 동일한 선상에서 사용하는 것이라 볼 수 있다.

KTable

- 메시지 키를 기준으로 묶어서 사용
- 유니크한 메시지 키를 기준으로 가장 최신 레코드를 사용
- 새로 데이터를 적재할 때 동일한 메시지 키가 있을 경우 데이터가 업데이트되었다고 볼 수 있다.

GlobalKTable

- KTable과 동일하게 메시지 키를 기준으로 묶어서 사용
- KTable로 선언된 토픽은 1개 파티션이 1개 태스크에 할당되어 사용되고, GlobalKTable 로 선언된 토픽은 모든 파티션 데이터가 각 태스크에 할당되어 사용된다는 차이점.
- KStream과 KTable 을 조인하려면 반드시 코파티셔닝되어 있어야 한다.

코파티셔닝

- 조인을 하는 2개 데이터의 파티션 개수가 동일하고 파티셔닝 전략을 동일하게 맞추는 작업
- 파티션 개수가 동일하고 파티셔닝 전략이 같은 경우에는 동일한 메시지 키를 가진 데이터가 동일한 태스크에 들어가는 것을 보장한다.

문제는 조인을 수행하려는 토픽들이 코파티셔닝되어 있음을 보장할 수 없다는 것.

코파티셔닝이 되지 않은 2개의 토픽을 조인하는 로직이 담긴 스트림즈 애플리케이션을 실행하면 TopologyException이 발생

코파티셔닝이 되어 있지 않으면 Kstream 또는 KTable을 리파티셔닝하는 과정을 거쳐야 한다.

리파티셔닝

- 새로운 토픽에 새로운 메시지 키를 가지도록 재배열하는 과정

코파티셔닝이 되어 있지 않은 2개의 토픽을 조인하기 위해 항상 리파티셔닝 과정을 거쳐야 할까?

리파티셔닝을 하는 과정은 토픽에 기존 데이터를 중복해서 생성할 뿐만 아니라 파티션을 재배열하기 위해 프로세싱하는 과정도 거쳐야 한다.

ㅇ스트림즈 애플리케이션의 로컬 스토리지의 사용량이 증가하고 네트워크로, 브로커에 부하가 생기므로 되도록이면 작은 용량의 데이터일 경우에만 사용하는 것이 좋다.

많은 양의 데이터를 가진 토픽으로 조인할 경우에는 리파티셔닝을 통해 KTable을 사용하는 것을 권장.

주요 옵션

```bash
bootstrap.servers : 호스트이름:포트
application.id : 고유 아이디 설정

# 옵셔널

default.key.serde: 키 직렬화, 역직렬화하는 클래스 지정
default.value.serde: 값 직렬화, 역직렬화하는 클래스 지정
num.stream.threads : 스트림 프로세싱 실행 시 실행될 스레드 개수 지정. 기본값 1
state.dir : rocksDB 저장소가 위치할 디렉토리를 지정
```

주요 함수

stream(), to()

- 특정 토픽의 데이터를 다른 토픽으로 전달하는 것.
- KStream의 데이터를 특정 토픽으로 저장하려면 스트림즈 DSL의 to() 메서드를 사용

filter()

- 토픽으로 들어오는 값에 대해 필터링하는 프로세스를 사용하여 만들 수 있다.

join()

- KTable과 KStream 은 메시지 키를 기준으로 조인할 수 있다.
- 카프카에서는 실시간으로 들어오는 데이터들을 조인할 수 있다.
- KTable과 KStream을 조인할 때 가장 중요한 것은 코파티셔닝이 되어 있는지 확인
- KTable로 사용할 토픽과 KStream 으로 사용할 토픽을 생성할 때 동일한 파티션 개수, 동일한 파티셔닝을 사용하는 것이 중요
- KTream, KTable, GlobalKTable 모두 동일한 토픽이고 다만, 스트림즈 애플리케이션 내부에서 사용할 때 메시지 키와 메시지 값을 사용하는 형태를 구분할 뿐인 것이다.

### 카프카 커넥트

카프카 오픈소스에 포함된 툴 중 하나로 데이터 파이프라인 생성 시 반복 작업을 줄이고 효율적인 전송을 이루기 위한 애플리케이션

파이프라인 생성 시 자주 반복되는 값들을 파라미터로 받는 커넥터를 코드로 작성하면 이후에 파이프라인을 실행할 때는 코드를 작성할 필요가 없기 때문이다.

프로듀서 역할을 하는 소스 커넥터와 컨슈머 역할을 하는 싱크 커넥터 2가지로 나뉜다.

MySQL, S3, MongoDB 등과 같은 저장소를 대표적인 싱크 애플리케이션, 소스 애플리케이션이라고 볼 수 있다.

카프카2.6에 포함된 커넥터를 실행할 경우 클러스터 간 토픽 미러링을 지원하는 미러메이커2와 파일 싱크 커넥터, 파일 소스 커넥터를 기본 플러그인으로 제공한다. 

오픈소스 커넥터는 직접 커넥터를 만들 필요가 없으며 커넥터 jar 파일을 다운로드하여 사용할 수 있다는 장점

사용자가 커넥트에 커넥터 생성 명령을 내리면 커넥트는 내부에 커넥터와 태스크를 생성한다. 

커넥터는 태스크들을 관리한다.

사용자가 커넥터를 사용하여 파이프라인을 생성할 때 컨버터와 트랜스폼 기능을 옵션으로 추가할 수 있다. 

컨버터는 데이터 처리를 하기 전에 스키마로 변경하도록 도와준다. ㅇ

트랜스폼은 데이터 처리 시 각 메시지 단위로 데이터를 간단하게 변환하기 위한 용도로 사용된다.

*커넥트를 실행하는 방법*

‘단일 모드 커넥트’와 ‘분산 모드 커넥트’

단일 모드 커넥트

- 1개 프로세스만 실행되는 점이 특징
- 단일 프로세스로 실행되기 때문에 고가용성 구성이 되지 않아서 SPOF가 될 수 있다.

분산 모드 커넥트

- 2대 이상의 서버에서 클러스터 형태로 운영함으로써 단일 모드 커넥트 대비 안전하게 운영할 수 있다는 장점
- 데이터 처리량의 변화에도 유연하게 대응할 수 있다.
- 운영에서는 2대 이상으로 구성할 것을 권장

### 소스 커넥터

소스 애플리케이션 또는 소스 파일로부터 데이터를 가져와 토픽으로 넣는 역할을 한다.

sourceConnector는 태스크를 실행하기 전 커넥터 설정파일을 초기화하고 어떤 태스크 클래스를 사용할 것인지 정의하는 데에 사용한다

SourceTask 만의 특징은 토픽에서 사용하는 오프셋이 아닌 자체적으로 사용하는 오프셋을 사용한다는 점

이 오프셋을 통해 데이터를 중복해서 토픽으로 보내는 것을 방지할 수 있다.

### 싱크 커넥터

싱크 커넥터는 토픽의 데이터를 타깃 애플리케이션 또는 타깃 파일로 저장하는 역할을 한다.

SinkConnector 와 SinkTask로 만든다.

SinkConnector 는 태스크를 실행하기 전에 사용자로부터 입력받은 설정값을 초기화하고 어떤 태스크 클래스를 사용할 것인지 정의하는 데에 사용

## 카프카 미러레이커2

서로 다른 두 개의 카프카 클러스터 간에 토픽을 복제하는 애플리케이션.

사용 이유

- 토픽의 모든 것을 복제할 필요성이 있기 때문

동일한 파티션에 동일한 레코드가 들어가도록 하는 작업은 복제하기 전 클러스터에서 사용하던 파티셔너에 대한 정보 없이 불가능.

복제하는 토픽의 파티션 개수가 달라진다면 복제된 데이터를 저장하는 토픽의 파티션도 개수가 달라져야 하므로, 어드민까지 조합한 형태로 개발이 필요.

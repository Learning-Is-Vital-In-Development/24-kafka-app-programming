# 3.5 카프카 스트림즈

- 카프카 스트림즈는 토픽에 적재된 데이터를 상태기반 또는 비상태기반으로 실시간 변환하여 다른 토픽에 적재하는 라이브러리이다.
- 스트림즈는 카프카에서 공식적으로 지원하는 라이브러리로 카프카 버전이 오를 때 스트림즈 라이브러리도 같이 릴리즈된다.
- 카프카 스트림즈는 스트림즈 애플리케이션 또는 카프카 브로커의 장애가 발생하더라도 정확히 한번 할 수 있도록 장애 허용 시스템을 가지고 있어 데이터 처리 안정성이 매우 뛰어나다.
    - 정확히 한번의 의미 : 데이터 처리 시스템이 장애나 중복 입력 등의 문제에도 불구하고, 각 데이터가 정확히 한 번만 처리되도록 보장하는 것
- 스트림즈 애플리케이션은 내부적으로 스레드를 1개 이상 생성할 수 있으며, 스레드는 1개 이상의 태스크를 가진다.
- 스트림즈의 태스크는 스트림즈 애플리케이션을 실행하면 생기는 데이터 처리 최소 단위이다. 만약 3개의 파티션으로 이루어진 토픽을 처리하는 스트림즈 애플리케이션을 실행하면 내부에 각각의 파티션을 처리할 3개의 태스크가 생긴다.
    - 스레드 수는 애플리케이션 설정에서 지정할 수 있다.
    - 스레드는 각 태스크를 순차적으로 처리하며, 동시에 여러 태스크를 처리할 수 없다. 따라서 처리율을 높이려면 스레드를 늘려 병렬 처리를 할 수 있다

---

### 토폴로지

- 2개 이상의 노드들과 선으로 이루어진 집합을 뜻한다.
- 스트림즈에서 사용하는 토폴로지는 트리 형태와 유사하다.
- 카프카 스트림즈에서는 토폴로지를 이루는 노드를 하나의 프로세서라고 부르고, 노드와 노드를 이은 선을 스트림이라고 부른다.
    - 스트림은 토픽의 데이터를 뜻하며 프로듀서와 컨슈머에서 활용했던 레코드와 동일하다.

- 소스 프로세서 : 데이터를 처리하기 위해 최초로 선언해야 하는 노드로, 하나 이상의 토픽에서 데이터를 가져오는 역할을 한다.
- 스트림 프로세서 : 다른 프로세서가 반환한 데이터를 처리하는 역할
- 싱크 프로세서 : 데이터를 특정 카프카 토픽으로 저장하는 역할을 하며 스트림즈로 처리된 데이터의 최종 종착지다.

---

- 카프카 스트림즈는 스트림즈DSL와 프로세서 API 2가지 방법으로 개발 가능하다.

### 스트림즈 DSL로 구현하는 데이터 처리

- 메시지 값을 기반으로 토픽 분기처리
- 지난 10분간 들어온 데이터의 개수 집계
- 토픽과 다른 토픽의 결합으로 새로운 데이터 생성

### 프로세서 API로 구현하는 데이터 처리 예시

- 메시지 값의 종류에 따라 토픽을 가변적으로 전송
- 일정한 시간 간격으로 데이터 처리
## 3.5.1 스트림즈 DSL

- 스트림즈 DSL에는 레코드의 흐름을 추상화한 3가지 개념인 KStream, KTable, GlobalKTable이 있다.

### KStream

- 레코드의 흐름을 표현한 것으로 Key-Value 형태이다(메시지 키-메시지 값)
- KStream으로 데이터를 조회하면 토픽에 존재하는 모든 레코드가 출력된다.
    - 컨슈머로 토픽을 구독하는 것과 동일한 선상

### KTable

- KTable은 KStream과 다르게 메시지 키를 기준으로 묶어서 사용한다.
- 메시지 키를 기준으로 가장 최신 추가된 레코드를 조회

### GlobalKTable

- KTable과 동일하게 메시지 키를 기준으로 묶어서 사용됨
- KTable로 선언된 토픽은 1개 파티션이 1개 태스크에 할당되어 사용되고, GlobalKTable로 선언된 토픽은 모든 파티션 데이터가 각 태스크에 할당되어 사용된다는 차이점이 있다.
    - 각 태스크는 GlobalKTable 의 모든 파티션 데이터를 로컬로 복제한다. 즉, 모든 태스크는 GlobalKTable의 전체 데이터를 가지고 있으며, 이를 통해 조회 연산이 빠르게 수행된다.
    - 코파티셔닝되지 않은 KStream과 KTable를 조인해서 사용하고 싶다면 KTable을 GlobalKTable로 선언해서 사용하면 된다.
        - GlobalKTable로 정의된 데이터는 모든 태스크에 동일하게 공유되기 때문에 코파티셔닝되지 않은 KStream과 조인이 가능
- 네트워크, 브로커에 부하가 생기므로 작은 용량의 데이터일 경우에만 사용하는 것이 좋음.

### 스트림즈 DSL - stream(), to()

```kotlin
class SimpleStreamApplication {
    companion object {
        private const val APPLICATION_NAME = "streams-application"
        private const val BOOTSTRAP_SERVERS = "my-kafka:9092"
        private const val STREAM_LOG = "stream_log"
        private const val STREAM_LOG_COPY = "stream_log_copy"
    }

    fun main(args: Array<String>) {
        val properties = Properties()
        // 애플리케이션 아이디값을 기준으로 병렬처리
        properties.put(StreamsConfig.APPLICATION_ID_CONFIG, APPLICATION_NAME)
        // 스트림즈 애플리케이션과 연동할 카프카 클러스터 정보를 입력
        properties.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS)
        // 역직렬화, 직렬화 방식 지정, 데이터를 처리할 때 메시지 키 또는 메시지 값을 역직렬화
        // 토픽에 넣을 때는 직렬화
        properties.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().javaClass)
        properties.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().javaClass)

				// 토폴로지를 정의하기 위함
        val builder = StreamsBuilder()
        // stream_log 토픽으로 부터 Kstream 객체를 만듦
        val streamLog = builder.stream<String, String>(STREAM_LOG)
        // 위에 KStream을 다른 토픽으로 전송하기 위해 to() 를 사용
        // to()는 KStream 인스턴스의 데이터들을 특정 토픽으로 저장하기 위한 용도로 사용(싱크 프로세서)
        streamLog.to(STREAM_LOG_COPY)

				// 정의한 토폴로지에 대한 정보와 스트림즈 실행을 위한 기본 옵션을 파라미터로 KafkaStreams
				// 인스턴스 생성 stream_log -> stream_log_copy(컨슈머 구독)
        val topology = builder.build()
        val streams = KafkaStreams(topology, properties)
        streams.start()
    }
}
```

### 스트림즈DSL - filter()

- 메시지 키 또는 메시지 값을 필터링하여 특정 조건에 맞는 데이터를 골라낼 때는 filter() 메서드를 사용하면 된다.

```kotlin
class StreamsFilter {
    companion object {
        private const val APPLICATION_NAME = "streams-filter-application"
        private const val BOOTSTRAP_SERVERS = "my-kafka:9092"
        private const val STREAM_LOG = "stream_log"
        private const val STREAM_LOG_FILTER = "stream_log_filter"
    }
    
    fun main(args: Array<String>) {
        val properties = Properties()
        properties.put(StreamsConfig.APPLICATION_ID_CONFIG, APPLICATION_NAME)
        properties.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS)
        properties.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().javaClass)
        properties.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().javaClass)

        val builder = StreamsBuilder()
        val streamLog = builder.stream<String, String>(STREAM_LOG)
        // 메시지 값의 길이가 5보다 큰 경우만 필터링
        val filteredStream = streamLog.filter { key, value -> value.length > 5 }
        filteredStream.to(STREAM_LOG_FILTER)

        val topology = builder.build()
        val streams = KafkaStreams(topology, properties)
        streams.start()
    }
}
```

### 스트림즈 DSL - KTable과 KStream을 join()

- KTable과 KStream은 메시지 키를 기준으로 조인할 수 있다.
    - 실시간으로 들어오는 데이터들을 조인할 수 있다.
    - 이름을 메시지 키, 주소를 메시지 값으로 가지고 있는 KTable / 이름을 메시지 키, 주문한 물품을 메시지 값으로 가지고 있는 KStream이 존재
    - 사용자가 물품을 주문하면 토픽에 저장된 이름:주소로 구성된 KTable과 조인하여 물품과 주소가 조합된 데이터를 새로 생성할 수 있다.
- 이벤트 데이터를 데이터베이스에 저장하지 않고도 조인하여 스트리밍 처리할 수 있다.
- KTable과 KStream을 조인할 때 가장 중요한 것은 코파티셔닝이 되어 있는지 확인하는 것이다.
    - KTable로 사용할 토픽과 KStream으로 사용할 토픽을 생성할 때 동일한 파티션 개수, 동일한 파티셔닝을 사용하는 것이 중요하다.
- KStream, KTable, GlobalKTable 모두 동일한 토픽이고, 스트림즈 애플리케이션 내부에서 사용할 때 메시지 키와 메시지 값을 사용하는 형태를 구분한다.

```kotlin
class KstreamJoinKTable {
    companion object {
        private const val APPLICATION_NAME = "streams-join-application"
        private const val BOOTSTRAP_SERVERS = "my-kafka:9092"
        private const val ADDRESS_TABLE = "address"
        private const val ORDER_STREAM = "order"
        private const val ORDER_JOIN_STREAM = "order_join"
    }

    fun main(args: Array<String>) {
        val properties = Properties()

        properties.put(StreamsConfig.APPLICATION_ID_CONFIG, APPLICATION_NAME)
        properties.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS)
        properties.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().javaClass)
        properties.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().javaClass)

        val builder = StreamsBuilder()
        val addressTable = builder.table<String, String>(ADDRESS_TABLE)
        val orderStream = builder.stream<String, String>(ORDER_STREAM)

        orderStream.join(addressTable) { order, address -> "$order send to $address" }
            .to(ORDER_JOIN_STREAM)

        val topology = builder.build()
        val streams = KafkaStreams(topology, properties)
        streams.start()

    }
}
```

### 스트림즈 DSL - GlobalKTable과 KStream을 join()

- 코파티셔닝되어 있지 않은 토픽을 조인해야 한다면 두 가지 방식이 있다
    - 리파티셔닝을 수행한 이후에 코파티셔닝이 된 상태로 조인 처리
    - KTable과 GlobalKTable을 Join

## 3.5.2 프로세서 API

- 프로세서 API는 스트림즈 DSL에서 제공하는 메서드들 보다 추가적인 상세 로직의 구현이 필요하다면 활용할 수 있다.
- 스트림즈 DSL에서 사용했던 KStream, KTable, GlobalKTable 개념이 없다는 점을 주의해야 한다.
- 프로세서 API에서 filter()와 동일한 로직을 구현하기 위해서는 스트림 프로세서 역할을 하는 클래스를 만들어야 한다.

```kotlin
class SimpleKafkaProcessor {
    companion object {
        private const val APPLICATION_NAME = "processor-application"
        private const val BOOTSTRAP_SERVERS = "my-kafka:9092"
        private const val STREAM_LOG = "stream_log"
        private const val STREAM_LOG_FILTER = "stream_log_filter"
    }

    fun main(args: Array<String>) {
        val properties = Properties()
        properties.put(StreamsConfig.APPLICATION_ID_CONFIG, APPLICATION_NAME)
        properties.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS)
        properties.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().javaClass)
        properties.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().javaClass)

        val topology = Topology()
        topology.addSource("Source", STREAM_LOG)
            .addProcessor("Process", { FilterProcessor() }, "Source")
            .addSink("Sink", STREAM_LOG_FILTER, "Process")

        val streams = KafkaStreams(topology, properties)
        streams.start()
    }
}
```